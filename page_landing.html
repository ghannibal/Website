<!doctype html>
<html lang="en" data-theme="dark">

<head>
    <fixed-header></fixed-header>
</head>

<style>
    main {
        position: absolute;
        left: 50%;
        top: 50%;
        transform: translate(-50%, -50%);
    }

    h1 {
        font-size: 3rem;
    }

    img {
        border-radius: 0.2rem;
        width: 6rem;
        margin-right: 0.5rem;
        float: left;
        filter: brightness(110%);
    }


    /* center the blockquote in the page */
    .blockquote-wrapper {
        display: flex;
        height: 45vh;
    }

    /* Blockquote main style */
    .blockquote {
        position: relative;
        font-family: 'Montserrat', sans-serif;
        font-weight: 800;
        color: #ffffff;
        padding: 20px 0;
        width: 100%;
        max-width: 500px;
        z-index: 1;
        margin: 80px auto;
        align-self: center;
        border-top: solid 1px;
        border-bottom: solid 1px;
    }

    /* Blockquote right double quotes */
    .blockquote:after {
        position: absolute;
        content: "‚Äù";
        color: rgba(255, 255, 255, 1);
        font-size: 10rem;
        line-height: 0;
        bottom: -43px;
        right: 30px;
    }

    /* increase header size after 600px */
    @media all and (min-width: 600px) {
        .blockquote h1 {
            font-size: 60px;
        }

    }
</style>

<body>
    <header></header>
    <main>
        <img src="photo.jpg">
        <hgroup>
            <h1><kbd>RESEARCHER</kbd></h1>
            <strong>
                <i>Trust and Explanations in Human-AI Interaction</i>
            </strong>
        </hgroup>
        <div class="blockquote-wrapper">
            <div class="blockquote">
                <h3>
                    Examining the double-edged nature of trust in the specific context of human-AI interaction is an
                    exciting
                    area of research because it also raises fundamental questions about what it means to be human.
                </h3>
            </div>
        </div>
        <!--<p>
            To unlock the full potential of AI, people must be able to trust AI-powered systems.
            Yet trust in AI also involves risk and uncertainty as AI-powered systems are imperfect, which leave people
            vulnerable.
            For this reason, the key question is not simply whether people can or should trust AI, but how that trust is
            formed and managed.
            Examining the double-edged nature of trust in the specific context of human-AI interaction is an exciting
            area of research, as it also raises fundamental questions about what it means to be human.
        </p>-->
        <button class="outline secondary">
            <a href="page_research.html">About My Work</a>
        </button>
        <!--<p>
            I am an independent Postdoc in the EXDIGIT project at the
            Department of Artificial Intelligence and Human Interfaces, University of Salzburg.
            I was previously a Postdoc in the Department of Artificial Intelligence at Ulm University and a Predoc
            in
            the Department of Visual Computing and Human-Centered Technology at TU Wien.
        </p>
        <p>
            I am a theory-driven researcher working on Human-AI Interaction (HAII)
            across various domains of application and with
            a focus on trust and explanations.
        </p>
        <p>
            You can reach me at <em>glenda.hannibal@plus.ac.at</em>
        </p>-->
    </main>
    <!--<fixed-footer></fixed-footer>-->
    <script src="./manager_fixed_headerfooter.js"></script>
</body>

</html>