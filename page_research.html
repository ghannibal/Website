<!doctype html>
<html lang="en" data-theme="dark">

<head>
    <fixed-header></fixed-header>
</head>

<style>
    img {
        width: 30rem;
        margin-left: 1.5rem;
        float: right;
        filter: grayscale(100%);
        /* flip */
        transform: rotateY(180deg);
    }

    c {
        color: #000000;
    }

    mark {
        float: right;
        margin-left: 0.3rem;
    }
</style>

<body>
    <header></header>
    <main class="container">
        <h1>RESEARCH</h1>
        <!--<img src="research2.jpg">-->
        <p>
            <!--
            To realize the full potential of Artificial Intelligence (AI), it is necessary that people trust in
            AI-powered systems (e.g., robots, recommender systems, agentic AI, autonomous vehicles, chatbots).
            At the same time, trusting AI-powered systems entails risk and uncertainty because AI is
            imperfect, which leaves people vulnerable when trust is unwarranted or misplaced.
            For this reason, it is not only important to understand whether people can or should trust in
            AI-powered systems.
            Studying the double-edge nature of trust within the specific context of human-AI interaction is incredible
            exciting research because it also brings fundamental questions about humanity to
            the forefront.
            <br>
            <br>
        -->
            My research belongs to the interdisciplinary field of Human-Computer Interaction (HCI)
            where I have a strong interest in <c>understanding and studying how people experience and interact with AI
                in everyday life contexts</c>. Within the HCI research community I have positioned myself as a
            theory-driven researcher working on Human-AI Interaction (HAII) across various domains of application (e.g.,
            social
            robots, recommender systems, robot process automation, agentic AI, autonomous vehicles) with a special focus
            on the relationship between (interpersonal) <c>trust and explanations</c>. To extend my expertise and to
            pursue a habilitation in HCI
            at University of Salzburg (Austria), I am currently working towards a comprehensive and systematic analysis
            of <c>mistrust and distrust in AI</c>. Understanding and studying the so-called “dark side of
            trust” in the specific context of HAII is important for tackling the black-box problem of complex AI
            systems, and I wish to fill
            this research gap by investigating why people are unwilling to trust in AI.
            <br>
            <mark>#human</mark><mark>#everyday life</mark><mark>#ai</mark>
            <br><br>
            My research covers a broad spectrum of human-centered and philosophical approaches to AI.
            On the technical and interactional side, I work in Human-AI Interaction and Explainable AI, examining how
            explanations shape understanding, trust, and reliance on AI systems, including recommender systems and
            agentic robot process automation. My work in Human-Robot Interaction and Social Robotics focuses on how
            people perceive, interact with, and attribute social meaning to embodied artificial agents.
            Complementing this applied research, I have a strong foundation in philosophy, including the philosophy of
            trust, philosophy of science, metaphysics, epistemology, and metaphilosophy. These perspectives allow me to
            <c>critically analyze the conceptual and normative assumptions underlying AI research and practice</c>.
            Together,
            this multidisciplinary reseaerch informs my work in AI and robot ethics, where I connect philosophical rigor
            with empirical and design-oriented insights to support the development of responsible, trustworthy, and
            human-centered AI and robotic systems.
            <br>
            <mark>#everyday life</mark><mark>#everyday life</mark><mark>#everyday life</mark><mark>#everyday life</mark>
            <br><br>
        </p>
        <!--
            <ul>
                <li>Human-AI Interaction</li>
                <li>Explainable AI</li>
                <li>Human-Robot Interaction</li>
                <li>Social Robotics</li>
                <li>Recommender Systems</li>
                <li>Agentic Robot Process Automation</li>
                <li>Philosophy of Trust</li>
                <li>Philosophy of Science</li>
                <li>Metaphysics</li>
                <li>Epistemology</li>
                <li>Metaphilosophy</li>
                <li>AI/Robot Ethics</li>
            </ul>-->
        <!--<details>
            <summary role="button" class="outline secondary">Conceptual Analysis, Modelling, and Engineering</summary>
            <p> I focus on understanding and advancing
                complex social and ethical notions (e.g., trust, agency, explainability, and vulnerability) in the
                context of human-AI and human-robot interaction.
                By integrating philosophical methods with system
                development andx design, I aim to ensure that these concepts are not only theoretically well-defined but
                also practically implementable.
                This work advances the scientific foundations of interdisciplinary AI
                research by improving conceptual clarity, enabling empirical study of abstract constructs, and informing
                the development of socially aware and ethically grounded technologies.
            </p>
        </details>
        <details>
            <summary role="button" class="outline secondary">Online User Research Studies</summary>
            <p>I have a particular interest in advancing user research methods,
                with a focus on designing and implementing novel experimental setups in online environments. I
                investigate how digital platforms can
                be used to study human interaction with AI systems in more scalable, diverse, and ecologically valid
                ways. By pushing the methodological boundaries of online experimentation, my work contributes to the
                development of robust, reproducible, and ethically sound approaches for empirical research in
                human-AI
                interaction. This enables more nuanced insights into user behavior, supports interdisciplinary
                theory-building, and informs the design of socially responsive AI technologies.
            </p>
        </details>
        <details>
            <summary role="button" class="outline secondary">Methodological Reflexivity and Metaphilosophical
                Perspectives
            </summary>
            <p>I am interested in drawing on knowledge, methods, or perspectives from one or more disciplines to
                address a question or problem. I have a particular focus on how philosophical thinking and methods can
                meaningfully contribute to advancing human-AI and human-robot interaction. I investigate how conceptual
                analysis, ethical reasoning, and critical reflection---core to the humanities and social sciences---can
                help clarify and operationalize key notions such as trust, everyday life, and social agency in AI-driven
                systems. This work not only deepens the theoretical and ethical foundations of the field but also
                demonstrates the essential role of humanities perspectives in the responsible development of emerging
                technologies.
            </p>
        </details>
        -->
    </main>
    <fixed-footer></fixed-footer>
    <script src="./manager_fixed_headerfooter.js"></script>
</body>

</html>